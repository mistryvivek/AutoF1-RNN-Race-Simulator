{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "15snMOHrwpWO_qNjB-uqVjM_LwzWq-JuP",
      "authorship_tag": "ABX9TyNBPVLbZwWqduM+tuPzADD9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mistryvivek/YRKCS-PRBX/blob/main/Model_1_Basic_NN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9BKFIobTm36L"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import random\n",
        "import pandas as pd\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from sklearn.preprocessing import OneHotEncoder"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'Using device: {device}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VOupk8NfiXR7",
        "outputId": "fbab08dd-f0ec-45a4-d5ba-958f5d90a6dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup Weights and Bias.\n",
        "\n",
        "* AI experimental tool."
      ],
      "metadata": {
        "id": "cnr6oqBffyAx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb -qU"
      ],
      "metadata": {
        "id": "cA-o8vzff3Y3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Log in to your W&B account\n",
        "import wandb\n",
        "import random\n",
        "import math"
      ],
      "metadata": {
        "id": "3F4388sHf7FM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.login()"
      ],
      "metadata": {
        "id": "0KY69sdrgAqC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "c3414712-36ca-49a0-e660-05fd46c8fb1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Make RNN"
      ],
      "metadata": {
        "id": "CUHwtkM2f4So"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RNN(nn.Module):\n",
        "    def __init__(self,max_laps,hidden_size):\n",
        "        super(RNN, self).__init__()\n",
        "        self.embedding =  nn.Embedding(max_laps, hidden_size)\n",
        "        self.linear_h = nn.Linear(hidden_size,hidden_size)\n",
        "        self.linear_y = nn.Linear(hidden_size,max_laps)\n",
        "        self.tahn = nn.Tanh()\n",
        "\n",
        "    def forward(self,x,hprev):\n",
        "        h = self.tahn(self.embedding(x) + self.linear_h(hprev))\n",
        "        y = self.linear_y(h)\n",
        "        return h,y"
      ],
      "metadata": {
        "id": "bWcnkSnqniIl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loss function (Based upon wk11 practical)\n",
        "\n",
        "* Vocab size is not relevent here - going to give it binary classification values anyway.\n",
        "* Everything else can be applied for time series: use Cross Entropy Loss, Length of the race = seq_len.\n",
        "* For each lap, pass through the RNN with previous hidden state and build up hte matrix of outputs.\n",
        "* Detact the previous hidden state as a new one will be generated."
      ],
      "metadata": {
        "id": "S81x8lmwJ68-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_loss(model,inputs,targets,hprev,max_tyre_life):\n",
        "  loss_func = nn.BCEWithLogitsLoss()\n",
        "  seq_length = len(inputs)\n",
        "  #outputs = torch.zeros(0, max_laps)\n",
        "  #print(outputs.shape)\n",
        "  for t in range(seq_length):\n",
        "    # For each character in the input sequence, pass through RNN with previous hidden state\n",
        "    hprev,y = model(inputs[t], hprev)\n",
        "    # Gradually build up matrix of output logits of size seq_length * max_tyre_life\n",
        "    #outputs = torch.cat((outputs ,y))\n",
        "\n",
        "  y = y[-1]\n",
        "\n",
        "  # Compute cross entropy loss for seq_length actual targets against estimated distributions\n",
        "  loss = loss_func(y,targets.squeeze(0))\n",
        "\n",
        "  # For truncated backprop, the next subsequence will use the final hidden state\n",
        "  # but will not backprop through it so we need to detach\n",
        "  hprev = hprev.detach()\n",
        "\n",
        "  return loss, hprev"
      ],
      "metadata": {
        "id": "4b01se5zoVVe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# My dataset - how to format?\n",
        "\n",
        "* Training and testing\n",
        "* inputs_training/ inputs_testing/  outputs_testing/ output_training\n",
        "* For now, it will all just be a 2d array.\n",
        "\n",
        "ERROR:\n",
        "\n",
        "```2551     return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)\n",
        "   2552\n",
        "   2553\n",
        "\n",
        "IndexError: index out of range in self```"
      ],
      "metadata": {
        "id": "icgJLYuiNA2T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BASE_PATH = r\"/content/drive/MyDrive/prbx_data/v1/\"\n",
        "max_race_size = 0\n",
        "\n",
        "# Define the logical ordering of compounds\n",
        "compound_order = {'SOFT': 1, 'MEDIUM': 2, 'HARD': 3, 'INTERMEDIATE': 4, 'WET': 5}"
      ],
      "metadata": {
        "id": "vjXV6o1kOB_-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TRAINING\n",
        "training_inputs = []\n",
        "training_outputs = []\n",
        "\n",
        "RaceCalender22 = pd.read_csv(BASE_PATH + r\"2022/eventCalender2022.csv\")\n",
        "for _, row in RaceCalender22.iterrows():\n",
        "    if row['EventFormat'] != 'testing':\n",
        "        # Load race data\n",
        "        TempRaceLoad = pd.read_csv(\n",
        "            BASE_PATH + f\"2022/{row['RoundNumber']}_{row['OfficialEventName']}/{row['RoundNumber']}_{row['OfficialEventName']}_Race.csv\".replace(\" \", \"_\")\n",
        "        )\n",
        "        for driver in TempRaceLoad['Driver'].unique():\n",
        "            # Filter data for the specific driver and sort by LapNumber\n",
        "            TempRaceLoadDriver = TempRaceLoad[TempRaceLoad['Driver'] == driver].sort_values(by='LapNumber', ascending=True)\n",
        "\n",
        "            if max(TempRaceLoadDriver['LapNumber']) > max_race_size:\n",
        "                max_race_size = max(TempRaceLoadDriver['LapNumber'])\n",
        "\n",
        "            # Extract tyre life and stint columns\n",
        "            tyre_life_array = TempRaceLoadDriver['TyreLife'].values\n",
        "            stint_array = TempRaceLoadDriver['Stint'].values\n",
        "            compound_array = TempRaceLoadDriver['Compound'].values\n",
        "\n",
        "            # Map compounds to ordinal values\n",
        "            compound_encoded = np.array([compound_order[compound] for compound in compound_array])\n",
        "\n",
        "            # Create the stint change array\n",
        "            stint_change_array = []\n",
        "            for i in range(len(stint_array)):\n",
        "                if i == len(stint_array) - 1:  # Last lap\n",
        "                    stint_change_array.append(False)  # Treat as no change\n",
        "                else:\n",
        "                    stint_change_array.append(stint_array[i] != stint_array[i + 1])\n",
        "\n",
        "            stint_change_array = np.array(stint_change_array)\n",
        "\n",
        "            # Ensure tyre_life_array and stint_change_array are properly formatted\n",
        "            tyre_life_array = torch.tensor(tyre_life_array, dtype=torch.long, device=device)\n",
        "            compound_encoded = torch.tensor(compound_encoded, dtype=torch.long, device=device).unsqueeze(1)\n",
        "            stint_change_array = torch.tensor(stint_change_array, dtype=torch.float32, device=device)\n",
        "\n",
        "            combined_inputs = torch.cat([tyre_life_array.unsqueeze(1), compound_encoded], dim=1)\n",
        "\n",
        "            # Add to training data\n",
        "            training_inputs.append(combined_inputs)\n",
        "            training_outputs.append(stint_change_array)"
      ],
      "metadata": {
        "id": "ub0zgeNtND3l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TESTING\n",
        "testing_inputs = []\n",
        "testing_outputs = []\n",
        "\n",
        "RaceCalender23 = pd.read_csv(BASE_PATH + r\"2023/eventCalender2023.csv\")\n",
        "for _, row in RaceCalender23.iterrows():\n",
        "    if row['EventFormat'] != 'testing':\n",
        "        # Load race data\n",
        "        TempRaceLoad = pd.read_csv(\n",
        "            BASE_PATH + f\"2023/{row['RoundNumber']}_{row['OfficialEventName']}/{row['RoundNumber']}_{row['OfficialEventName']}_Race.csv\".replace(\" \", \"_\")\n",
        "        )\n",
        "        for driver in TempRaceLoad['Driver'].unique():\n",
        "            # Filter data for the specific driver and sort by LapNumber\n",
        "            TempRaceLoadDriver = TempRaceLoad[TempRaceLoad['Driver'] == driver].sort_values(by='LapNumber', ascending=True)\n",
        "\n",
        "            if max(TempRaceLoadDriver['LapNumber']) > max_race_size:\n",
        "                max_race_size = max(TempRaceLoadDriver['LapNumber'])\n",
        "\n",
        "            # Extract tyre life and stint columns\n",
        "            tyre_life_array = TempRaceLoadDriver['TyreLife'].values\n",
        "            stint_array = TempRaceLoadDriver['Stint'].values\n",
        "            compound_array = TempRaceLoadDriver['Compound'].values\n",
        "\n",
        "            # Map compounds to ordinal values\n",
        "            compound_encoded = np.array([compound_order[compound] for compound in compound_array])\n",
        "\n",
        "            # Create the stint change array\n",
        "            stint_change_array = []\n",
        "            for i in range(len(stint_array)):\n",
        "                if i == len(stint_array) - 1:  # Last lap\n",
        "                    stint_change_array.append(False)  # Treat as no change\n",
        "                else:\n",
        "                    stint_change_array.append(stint_array[i] != stint_array[i + 1])\n",
        "\n",
        "            stint_change_array = np.array(stint_change_array)\n",
        "\n",
        "            # Ensure tyre_life_array and stint_change_array are properly formatted\n",
        "            tyre_life_array = torch.tensor(tyre_life_array, dtype=torch.long, device=device)\n",
        "            compound_encoded = torch.tensor(compound_encoded, dtype=torch.long, device=device).unsqueeze(1)\n",
        "            stint_change_array = torch.tensor(stint_change_array, dtype=torch.float32, device=device)\n",
        "\n",
        "            combined_inputs = torch.cat([tyre_life_array.unsqueeze(1), compound_encoded], dim=1)\n",
        "\n",
        "            # Add to testing data\n",
        "            testing_inputs.append(combined_inputs)\n",
        "            testing_outputs.append(stint_change_array)"
      ],
      "metadata": {
        "id": "MQHvjvglTQNF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training the model\n",
        "\n",
        "* https://developers.google.com/machine-learning/crash-course/overfitting/interpreting-loss-curves"
      ],
      "metadata": {
        "id": "4015h9tIT5Lj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_size = 10\n",
        "lr = 0.01\n",
        "iterations = 10000\n",
        "max_race_size = int(max_race_size)\n",
        "input_parameters = ['TyreLife']\n",
        "dataset = 'v1'\n",
        "\n",
        "lr_experiments = [0.01, 0.05, 0.001, 0.005]"
      ],
      "metadata": {
        "id": "s-1yQVYSUMBf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(inputs, outputs, tolerance=3):\n",
        "    total_correct = 0\n",
        "    total_predictions = 0\n",
        "\n",
        "    for seq_idx in range(len(inputs)):\n",
        "        # Initialize hidden state for each sequence\n",
        "        hprev = torch.zeros(hidden_size, device=device)\n",
        "\n",
        "        # Get the input and target sequences\n",
        "        input = inputs[seq_idx]\n",
        "        output = outputs[seq_idx].cpu().numpy()\n",
        "\n",
        "        # Step through the input sequence and get predicted probabilities\n",
        "        for t in range(len(input)):\n",
        "            hprev, y = model(torch.tensor(input[t], device=device), hprev)\n",
        "            predicted_pits = torch.sigmoid(y) # Apply sigmoid to logits to get probabilities\n",
        "\n",
        "        y = y[-1]\n",
        "\n",
        "        predicted_pits = predicted_pits.cpu().detach().numpy()[0]\n",
        "        predicted_pits = predicted_pits > 0.5\n",
        "        actual_pits = output == 1.0\n",
        "\n",
        "        # Now check accuracy for this sequence with tolerance\n",
        "        correct_count = 0\n",
        "        total_predictions_for_sequence = 0\n",
        "\n",
        "        for predicted_pit_idx in range(len(predicted_pits)):\n",
        "          if predicted_pits[predicted_pit_idx]:  # If a pit stop is predicted\n",
        "              total_predictions += 1\n",
        "\n",
        "              # Calculate the tolerance window around the predicted pit\n",
        "              start_idx = max(0, predicted_pit_idx - tolerance)\n",
        "              end_idx = min(len(actual_pits), predicted_pit_idx + tolerance + 1)\n",
        "\n",
        "              # Check if there's any actual pit stop within this window using NumPy\n",
        "              if np.any(actual_pits[start_idx:end_idx] == 1):  # If there's a pit stop in this window\n",
        "                  correct_count += 1\n",
        "                  break\n",
        "\n",
        "        total_correct += correct_count\n",
        "\n",
        "    # Calculate overall accuracy\n",
        "    accuracy = total_correct / total_predictions if total_predictions > 0 else 0\n",
        "    return accuracy * 100"
      ],
      "metadata": {
        "id": "taRdShcOzWeY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pad_with_last_value(tensor, max_race_size):\n",
        "    if len(tensor) >= max_race_size:\n",
        "        return tensor\n",
        "\n",
        "    last_value = tensor[-1]\n",
        "\n",
        "    # TO FIX: RuntimeError: a Tensor with 6 elements cannot be converted to Scalar\n",
        "    # After adding compound\n",
        "    if last_value.ndimension() > 0:\n",
        "        padding = last_value.unsqueeze(0).repeat(max_race_size - len(tensor), 1)\n",
        "    else:\n",
        "        padding = torch.full((max_race_size - len(tensor),), last_value.item(), dtype=tensor.dtype, device=device)\n",
        "\n",
        "    return torch.cat((tensor, padding))"
      ],
      "metadata": {
        "id": "_Km1hhBTVm7G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizers = {\n",
        "    \"SGD\": torch.optim.SGD,  # Stochastic Gradient Descent\n",
        "    #\"RMSprop\": torch.optim.RMSprop,  # Root Mean Square Propagation\n",
        "    #\"Adagrad\": torch.optim.Adagrad,  # Adaptive Gradient Algorithm\n",
        "    #\"Adadelta\": torch.optim.Adadelta,  # Adaptive Delta\n",
        "    #\"AdamW\": torch.optim.AdamW,  # Adam with decoupled weight decay\n",
        "    #\"NAdam\": torch.optim.NAdam,  # Nesterov-accelerated Adaptive Moment Estimation\n",
        "    #\"ASGD\": torch.optim.ASGD,  # Averaged Stochastic Gradient Descent\n",
        "    #\"SparseAdam\": torch.optim.SparseAdam,  # Optimizer for sparse tensors\n",
        "    #\"Rprop\": torch.optim.Rprop,  # Resilient Backpropagation\n",
        "}\n",
        "\n",
        "permutation = torch.randperm(len(training_inputs))\n",
        "training_inputs = [training_inputs[i] for i in permutation]\n",
        "training_outputs = [training_outputs[i] for i in permutation]\n",
        "\n",
        "for lr in lr_experiments:\n",
        "  model = RNN(max_race_size, hidden_size)\n",
        "  model = model.to(device)\n",
        "\n",
        "  optim = optimizers[\"SGD\"](model.parameters(), lr = lr)\n",
        "\n",
        "\n",
        "  # Initialize WandB\n",
        "  wandb.init(\n",
        "      project=\"prbx-model-v1\",\n",
        "      config={\n",
        "          \"learning_rate\": lr,\n",
        "          \"iterations\": iterations,\n",
        "          \"hidden_size\": hidden_size,\n",
        "          \"max_race_size\": max_race_size,\n",
        "          \"input_parameters\": input_parameters,\n",
        "          \"dataset\": dataset,\n",
        "          \"optimizer\": \"SGD\",\n",
        "          \"random_perms\": True,\n",
        "          \"compound_formatting\": \"logical_ordering\",\n",
        "          \"tanh_alternative\": \"relu\",\n",
        "          \"gradient_clipping_method\": \"fixed 1.0 max norm\"\n",
        "      }\n",
        "  )\n",
        "\n",
        "  n, p = 0, 0\n",
        "  while n<=iterations:\n",
        "    hprev = torch.zeros(hidden_size,) # reset RNN memory\n",
        "\n",
        "    inputs = training_inputs[p]\n",
        "    targets = training_outputs[p]\n",
        "\n",
        "    inputs = pad_with_last_value(inputs, max_race_size).to(device)\n",
        "    targets = pad_with_last_value(targets, max_race_size).to(device)\n",
        "    hprev = torch.zeros(hidden_size, device=device)\n",
        "\n",
        "    # Compute loss for current subsequence\n",
        "    loss, hprev = calculate_loss(model,inputs,targets,hprev,max_race_size)\n",
        "    optim.zero_grad()\n",
        "    loss.backward()\n",
        "\n",
        "    # Clip gradients\n",
        "    max_norm = 1.0  # Maximum norm for gradients\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm)\n",
        "\n",
        "    optim.step()\n",
        "\n",
        "    if n % 500 == 0:\n",
        "      print('[{:}] Loss: {:.2f}'.format(n,loss.item()))\n",
        "      testing_accuracy = evaluate_model(testing_inputs,testing_outputs)\n",
        "      training_accuracy = evaluate_model(training_inputs,training_outputs)\n",
        "\n",
        "      # Log metrics to WandB\n",
        "      wandb.log({\n",
        "          \"iteration\": n,\n",
        "          \"loss\": loss.item(),\n",
        "          \"training_accuracy\": training_accuracy,\n",
        "          \"testing_accuracy\": testing_accuracy,\n",
        "      })\n",
        "\n",
        "      # Save to weights and biases.\n",
        "      model_path = \"model.pth\"\n",
        "      torch.save(model.state_dict(), model_path)\n",
        "\n",
        "\n",
        "      artifact = wandb.Artifact(\"basic-rnn-binary-classifier\", type=\"model\")\n",
        "      artifact.add_file(model_path)\n",
        "      wandb.log_artifact(artifact)\n",
        "\n",
        "    n += 1 # iteration counter\n",
        "    p += 1 # dataset counter\n",
        "\n",
        "    #Restart to the front of the list.\n",
        "    if len(training_inputs) - 1 == p:\n",
        "      p = 0\n",
        "      permutation = torch.randperm(len(training_inputs))\n",
        "      training_inputs = [training_inputs[i] for i in permutation]\n",
        "      training_outputs = [training_outputs[i] for i in permutation]"
      ],
      "metadata": {
        "id": "oxZaedx7T8Ch"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#How can we calculate accuracy for this basic model?\n",
        "\n",
        "* Say is probability is above 80% percent pit, otherwise don't pit.\n",
        "* Want at least one right pit stop identification to class it as match."
      ],
      "metadata": {
        "id": "0LwWuY-xc-c_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for t in range(len(testing_inputs[1])):\n",
        "  # For each character in the input sequence, pass through RNN with previous hidden state\n",
        "  hprev,y = model(torch.tensor(testing_inputs[1][t], device=device),hprev)\n",
        "probabilities = torch.sigmoid(y)"
      ],
      "metadata": {
        "id": "Vdeo3NuEsA3b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "probabilities[-1]"
      ],
      "metadata": {
        "id": "fEWvwpJ2sT2v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for t in range(len(training_inputs[0])):\n",
        "  # For each character in the input sequence, pass through RNN with previous hidden state\n",
        "  hprev,y = model(torch.tensor(training_inputs[0][t], device=device),hprev)\n",
        "probabilities = torch.sigmoid(y)"
      ],
      "metadata": {
        "id": "8Xf23b3VsfGF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "probabilities[-1]"
      ],
      "metadata": {
        "id": "mxvmEKgxsizL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Plot to see what this basic model has remembered - probably just averages"
      ],
      "metadata": {
        "id": "dTW5sj-0rpEs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Validating my data"
      ],
      "metadata": {
        "id": "EQrJxg_CXdKZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(training_inputs) == len(training_outputs)"
      ],
      "metadata": {
        "id": "8i2tG_ZxXEmu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_inputs[0].shape"
      ],
      "metadata": {
        "id": "QT6aLRA5dPL9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_outputs[0].shape"
      ],
      "metadata": {
        "id": "QuompqxedSuP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modify code for sliding window approach (like wk11 code).\n",
        "\n",
        "* Look at the full race image instead.\n",
        "* What data types are in the wk11 practical.\n",
        "* No vocab size required because they apply to catogorical contexts."
      ],
      "metadata": {
        "id": "0vxpMwPmrCNG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BASE_PATH = r\"/content/drive/MyDrive/prbx_data/v1/\"\n",
        "max_race_size = 0\n",
        "max_tyre_life = 0"
      ],
      "metadata": {
        "id": "VEYJqy9UAizz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TRAINING\n",
        "training_inputs = []\n",
        "training_outputs = []\n",
        "\n",
        "RaceCalender22 = pd.read_csv(BASE_PATH + r\"2022/eventCalender2022.csv\")\n",
        "for _, row in RaceCalender22.iterrows():\n",
        "    if row['EventFormat'] != 'testing':\n",
        "        TempRaceLoad = pd.read_csv(\n",
        "            BASE_PATH + f\"2022/{row['RoundNumber']}_{row['OfficialEventName']}/{row['RoundNumber']}_{row['OfficialEventName']}_Race.csv\".replace(\" \", \"_\")\n",
        "        )\n",
        "        for driver in TempRaceLoad['Driver'].unique():\n",
        "            TempRaceLoadDriver = TempRaceLoad[TempRaceLoad['Driver'] == driver].sort_values(by='LapNumber', ascending=True)\n",
        "            tyre_life_array = TempRaceLoadDriver['TyreLife'].values\n",
        "            stint_array = TempRaceLoadDriver['Stint'].values\n",
        "\n",
        "            if max(TempRaceLoadDriver['LapNumber']) > max_race_size:\n",
        "                max_race_size = max(TempRaceLoadDriver['LapNumber'])\n",
        "\n",
        "            if max(TempRaceLoadDriver['TyreLife']) > max_tyre_life:\n",
        "                max_tyre_life = max(TempRaceLoadDriver['TyreLife'])\n",
        "\n",
        "            stint_change_array = [0 if stint_array[i] == stint_array[i + 1]else 1\n",
        "                                  for i in range(len(stint_array) - 1)] + [0]\n",
        "            stint_change_array = np.array(stint_change_array)\n",
        "\n",
        "            training_inputs.append(tyre_life_array)\n",
        "            training_outputs.append(stint_change_array)"
      ],
      "metadata": {
        "id": "muIWawoGrFrn"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TESTING\n",
        "testing_inputs = []\n",
        "testing_outputs = []\n",
        "\n",
        "RaceCalender23 = pd.read_csv(BASE_PATH + r\"2023/eventCalender2023.csv\")\n",
        "for _, row in RaceCalender23.iterrows():\n",
        "    if row['EventFormat'] != 'testing':\n",
        "        TempRaceLoad = pd.read_csv(\n",
        "            BASE_PATH + f\"2023/{row['RoundNumber']}_{row['OfficialEventName']}/{row['RoundNumber']}_{row['OfficialEventName']}_Race.csv\".replace(\" \", \"_\")\n",
        "        )\n",
        "        for driver in TempRaceLoad['Driver'].unique():\n",
        "            TempRaceLoadDriver = TempRaceLoad[TempRaceLoad['Driver'] == driver].sort_values(by='LapNumber', ascending=True)\n",
        "            tyre_life_array = TempRaceLoadDriver['TyreLife'].values\n",
        "            stint_array = TempRaceLoadDriver['Stint'].values\n",
        "\n",
        "            if max(TempRaceLoadDriver['LapNumber']) > max_race_size:\n",
        "                max_race_size = max(TempRaceLoadDriver['LapNumber'])\n",
        "\n",
        "            if max(TempRaceLoadDriver['TyreLife']) > max_tyre_life:\n",
        "                max_tyre_life = max(TempRaceLoadDriver['TyreLife'])\n",
        "\n",
        "            stint_change_array = [0 if stint_array[i] == stint_array[i + 1]else 1\n",
        "                                  for i in range(len(stint_array) - 1)] + [0]\n",
        "            stint_change_array = np.array(stint_change_array)\n",
        "\n",
        "            testing_inputs.append(tyre_life_array)\n",
        "            testing_outputs.append(stint_change_array)"
      ],
      "metadata": {
        "id": "fEz0-Y5DrrEr"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RNNv1b(nn.Module):\n",
        "    def __init__(self,vocab_size,hidden_size):\n",
        "        super(RNNv1b, self).__init__()\n",
        "        self.embedding =  nn.Embedding(vocab_size, hidden_size)\n",
        "        self.linear_h = nn.Linear(hidden_size,hidden_size)\n",
        "        self.linear_y = nn.Linear(hidden_size,1)\n",
        "        self.tanh = nn.Tanh()\n",
        "\n",
        "    def forward(self,x,hprev):\n",
        "        h = self.tanh(self.embedding(x) + self.linear_h(hprev))\n",
        "        y = self.linear_y(h)\n",
        "        return h,y"
      ],
      "metadata": {
        "id": "SbssajRW_yHx"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_loss(model,inputs,targets,hprev,vocab_size):\n",
        "  loss_func = nn.BCEWithLogitsLoss()\n",
        "  seq_length = len(inputs)\n",
        "  outputs = []\n",
        "  for t in range(seq_length):\n",
        "    # For each character in the input sequence, pass through RNN with previous hidden state\n",
        "    hprev,y = model(torch.tensor([inputs[t]], device=device),hprev)\n",
        "    # Gradually build up matrix of output logits of size seq_length * vocab_size - we want it at every time step do not want this.\n",
        "    # Compute cross entropy loss for seq_length actual targets against estimated distributions\n",
        "    # RuntimeError: result type Float can't be cast to the desired output type Long\n",
        "    outputs.append(y)\n",
        "\n",
        "  outputs = torch.stack(outputs).squeeze(1).squeeze(1)\n",
        "  loss = loss_func(outputs ,targets)\n",
        "\n",
        "  # For truncated backprop, the next subsequence will use the final hidden state\n",
        "  # but will not backprop through it so we need to detach\n",
        "  hprev = hprev.detach()\n",
        "\n",
        "  return loss, hprev"
      ],
      "metadata": {
        "id": "Kblub6lCs1q9"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model parameters to be logged by w and b.\n",
        "hidden_size = 10\n",
        "lr = 0.001\n",
        "iterations = 5000\n",
        "input_parameters = ['TyreLife']\n",
        "dataset = 'v1'\n",
        "vocab_size = int(max_tyre_life) + 1 # Possiblity for each tyre_life"
      ],
      "metadata": {
        "id": "ZEPgYoM5tVB7"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PADDING\n",
        "def add_padding(max_race_size, sequence):\n",
        "    if len(sequence) >= max_race_size:\n",
        "        return sequence[:max_race_size]\n",
        "    else:\n",
        "        padding = [0] * (max_race_size - len(sequence))\n",
        "        return np.concatenate([sequence,padding])"
      ],
      "metadata": {
        "id": "kZnrmrWCZewQ"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = RNNv1b(vocab_size,hidden_size)\n",
        "model.to(device)\n",
        "\n",
        "optim = torch.optim.Adam(model.parameters(), lr = lr)\n",
        "\n",
        "n, p = 0, 0\n",
        "while n<=iterations:\n",
        "  hprev = torch.zeros(hidden_size, device=device) # reset RNN memory\n",
        "\n",
        "  # Why apply padding here\n",
        "  inputs = add_padding(int(max_race_size),training_inputs[p])\n",
        "  outputs = add_padding(int(max_race_size),training_outputs[p])\n",
        "\n",
        "  # Extract next subsequence of characters\n",
        "  inputs = torch.tensor(training_inputs[p],dtype=torch.long, device=device)\n",
        "  targets = torch.tensor(training_outputs[p],dtype=torch.float32, device=device)\n",
        "\n",
        "  # Compute loss for current subsequence\n",
        "  loss, hprev = calculate_loss(model,inputs,targets,hprev,vocab_size)\n",
        "  optim.zero_grad()\n",
        "  loss.backward()\n",
        "  optim.step()\n",
        "\n",
        "  if n % 500 == 0:\n",
        "    print('[{:}] Loss: {:.2f}'.format(n,loss.item()))\n",
        "    check_accuracy()\n",
        "\n",
        "  p += 1 # move data pointer\n",
        "  n += 1 # iteration counter\n",
        "\n",
        "  if p == int(max_race_size) - 1:\n",
        "    p = 0"
      ],
      "metadata": {
        "id": "NjMwOzL7uykr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf441997-373c-45b1-cc30-61f7d97a165c"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0] Loss: 0.56\n",
            "Total Accuracy: 86.3056851615204\n",
            "Total No Pit Accuracy: 97.59737403133566\n",
            "Total Pit Accuracy (+/- 3 LAPS): 17.447535383113713\n",
            "Total Pit Predictions: 4098\n",
            "[500] Loss: 0.12\n",
            "Total Accuracy: 95.79185116942554\n",
            "Total No Pit Accuracy: 97.45190122708681\n",
            "Total Pit Accuracy (+/- 3 LAPS): 21.8944099378882\n",
            "Total Pit Predictions: 644\n",
            "[1000] Loss: 0.02\n",
            "Total Accuracy: 95.79185116942554\n",
            "Total No Pit Accuracy: 97.45190122708681\n",
            "Total Pit Accuracy (+/- 3 LAPS): 21.8944099378882\n",
            "Total Pit Predictions: 644\n",
            "[1500] Loss: 0.15\n",
            "Total Accuracy: 94.42182531427382\n",
            "Total No Pit Accuracy: 97.47123607949302\n",
            "Total Pit Accuracy (+/- 3 LAPS): 19.860017497812773\n",
            "Total Pit Predictions: 1143\n",
            "[2000] Loss: 0.19\n",
            "Total Accuracy: 95.85723201283842\n",
            "Total No Pit Accuracy: 97.34179127020087\n",
            "Total Pit Accuracy (+/- 3 LAPS): 19.485294117647058\n",
            "Total Pit Predictions: 544\n",
            "[2500] Loss: 0.07\n",
            "Total Accuracy: 95.85723201283842\n",
            "Total No Pit Accuracy: 97.34179127020087\n",
            "Total Pit Accuracy (+/- 3 LAPS): 19.485294117647058\n",
            "Total Pit Predictions: 544\n",
            "[3000] Loss: 0.11\n",
            "Total Accuracy: 95.91666914321377\n",
            "Total No Pit Accuracy: 97.32053951298995\n",
            "Total Pit Accuracy (+/- 3 LAPS): 18.11023622047244\n",
            "Total Pit Predictions: 508\n",
            "[3500] Loss: 0.02\n",
            "Total Accuracy: 95.91666914321377\n",
            "Total No Pit Accuracy: 97.32053951298995\n",
            "Total Pit Accuracy (+/- 3 LAPS): 18.11023622047244\n",
            "Total Pit Predictions: 508\n",
            "[4000] Loss: 0.06\n",
            "Total Accuracy: 95.91964099973254\n",
            "Total No Pit Accuracy: 97.31205502594426\n",
            "Total Pit Accuracy (+/- 3 LAPS): 17.16566866267465\n",
            "Total Pit Predictions: 501\n",
            "[4500] Loss: 0.07\n",
            "Total Accuracy: 95.91964099973254\n",
            "Total No Pit Accuracy: 97.31205502594426\n",
            "Total Pit Accuracy (+/- 3 LAPS): 17.16566866267465\n",
            "Total Pit Predictions: 501\n",
            "[5000] Loss: 0.06\n",
            "Total Accuracy: 95.91666914321377\n",
            "Total No Pit Accuracy: 97.31482878262182\n",
            "Total Pit Accuracy (+/- 3 LAPS): 17.261904761904763\n",
            "Total Pit Predictions: 504\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def check_accuracy():\n",
        "  sigmoid = nn.Sigmoid()\n",
        "  total, matches = 0, 0\n",
        "  no_pit_prediction_total, correct_no_pit_prediction = 0,0\n",
        "  pit_prediction_total, correct_pit_prediction = 0,0\n",
        "\n",
        "  for t in range(len(testing_inputs) - 1):\n",
        "      inputs = add_padding(int(max_race_size),testing_inputs[t])\n",
        "      outputs = add_padding(int(max_race_size),testing_outputs[t])\n",
        "\n",
        "      for x in range(len(inputs) - 1):\n",
        "        hprev = torch.zeros(hidden_size, device=device)\n",
        "        hprev, y = model(torch.tensor([inputs[x]], device=device, dtype=torch.long), hprev)\n",
        "        y = sigmoid(y.squeeze(0))\n",
        "\n",
        "        if (y.item() > 0.5) == (outputs[x] == 1.0):\n",
        "          matches += 1\n",
        "\n",
        "        if (y.item() > 0.5):\n",
        "          pit_prediction_total += 1\n",
        "          if 1 in outputs[max(0, x - 2): min(int(max_race_size), x+4)]:\n",
        "              correct_pit_prediction += 1\n",
        "        else:\n",
        "          no_pit_prediction_total += 1\n",
        "          if y.floor().item() == outputs[x]:\n",
        "              correct_no_pit_prediction += 1\n",
        "\n",
        "        total += 1\n",
        "\n",
        "  if total != 0:\n",
        "    print(f\"Total Accuracy: {matches / total * 100}\")\n",
        "  else:\n",
        "    print(\"Total Accuracy: 0.0\")\n",
        "\n",
        "  if no_pit_prediction_total != 0:\n",
        "    print(f\"Total No Pit Accuracy: {correct_no_pit_prediction / no_pit_prediction_total * 100}\")\n",
        "  else:\n",
        "    print(f\"Total No Pit Accuracy: 0.0\")\n",
        "\n",
        "  if pit_prediction_total != 0:\n",
        "    print(f\"Total Pit Accuracy (+/- 3 LAPS): {correct_pit_prediction / pit_prediction_total * 100}\")\n",
        "  else:\n",
        "    print(f\"Total Pit Accuracy (+/- 3 LAPS): 0.0\")\n",
        "\n",
        "  print(f\"Total Pit Predictions: {pit_prediction_total}\")"
      ],
      "metadata": {
        "id": "TmkbKIyMSOeA"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "check_accuracy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fE8CI5yPeeFL",
        "outputId": "16f874c4-dc0d-4510-dfb0-7d46df9dcfde"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Accuracy: 95.91666914321377\n",
            "Total No Pit Accuracy: 97.31482878262182\n",
            "Total Pit Accuracy (+/- 3 LAPS): 17.261904761904763\n",
            "Total Pit Predictions: 504\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modify code to help with overfitting to the majority class"
      ],
      "metadata": {
        "id": "C8wEwOYFhkde"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TRAINING\n",
        "training_inputs = []\n",
        "training_outputs = []\n",
        "\n",
        "RaceCalender22 = pd.read_csv(BASE_PATH + r\"2022/eventCalender2022.csv\")\n",
        "for _, row in RaceCalender22.iterrows():\n",
        "    if row['EventFormat'] != 'testing':\n",
        "        TempRaceLoad = pd.read_csv(\n",
        "            BASE_PATH + f\"2022/{row['RoundNumber']}_{row['OfficialEventName']}/{row['RoundNumber']}_{row['OfficialEventName']}_Race.csv\".replace(\" \", \"_\")\n",
        "        )\n",
        "        for driver in TempRaceLoad['Driver'].unique():\n",
        "            TempRaceLoadDriver = TempRaceLoad[TempRaceLoad['Driver'] == driver].sort_values(by='LapNumber', ascending=True)\n",
        "            tyre_life_array = TempRaceLoadDriver['TyreLife'].values\n",
        "            stint_array = TempRaceLoadDriver['Stint'].values\n",
        "\n",
        "            if max(TempRaceLoadDriver['LapNumber']) > max_race_size:\n",
        "                max_race_size = max(TempRaceLoadDriver['LapNumber'])\n",
        "\n",
        "            if max(TempRaceLoadDriver['TyreLife']) > max_tyre_life:\n",
        "                max_tyre_life = max(TempRaceLoadDriver['TyreLife'])\n",
        "\n",
        "            stint_change_array = [0 if stint_array[i] == stint_array[i + 1] else 1\n",
        "                                  for i in range(len(stint_array) - 1)] + [0]\n",
        "            stint_change_array = np.array(stint_change_array)\n",
        "            mandatory_change_made = [1 if stint_array[i] == 1 else 0\n",
        "                                     for i in range(len(stint_array))]\n",
        "            mandatory_change_made = np.array(mandatory_change_made)\n",
        "\n",
        "            combined_array = np.stack([stint_change_array, mandatory_change_made], axis=1)\n",
        "\n",
        "            training_inputs.append(combined_array)\n",
        "            training_outputs.append(stint_change_array)"
      ],
      "metadata": {
        "id": "wmhuuNiHhnhP"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TESTING\n",
        "testing_inputs = []\n",
        "testing_outputs = []\n",
        "\n",
        "RaceCalender23 = pd.read_csv(BASE_PATH + r\"2023/eventCalender2023.csv\")\n",
        "for _, row in RaceCalender23.iterrows():\n",
        "    if row['EventFormat'] != 'testing':\n",
        "        TempRaceLoad = pd.read_csv(\n",
        "            BASE_PATH + f\"2023/{row['RoundNumber']}_{row['OfficialEventName']}/{row['RoundNumber']}_{row['OfficialEventName']}_Race.csv\".replace(\" \", \"_\")\n",
        "        )\n",
        "        for driver in TempRaceLoad['Driver'].unique():\n",
        "            TempRaceLoadDriver = TempRaceLoad[TempRaceLoad['Driver'] == driver].sort_values(by='LapNumber', ascending=True)\n",
        "            tyre_life_array = TempRaceLoadDriver['TyreLife'].values\n",
        "            stint_array = TempRaceLoadDriver['Stint'].values\n",
        "\n",
        "            if max(TempRaceLoadDriver['LapNumber']) > max_race_size:\n",
        "                max_race_size = max(TempRaceLoadDriver['LapNumber'])\n",
        "\n",
        "            if max(TempRaceLoadDriver['TyreLife']) > max_tyre_life:\n",
        "                max_tyre_life = max(TempRaceLoadDriver['TyreLife'])\n",
        "\n",
        "            stint_change_array = [0 if stint_array[i] == stint_array[i + 1]else 1\n",
        "                                  for i in range(len(stint_array) - 1)] + [0]\n",
        "            stint_change_array = np.array(stint_change_array)\n",
        "            mandatory_change_made = [1 if stint_array[i] == 1 else 0\n",
        "                                     for i in range(len(stint_array))]\n",
        "            mandatory_change_made = np.array(mandatory_change_made)\n",
        "\n",
        "            combined_array = np.stack([stint_change_array, mandatory_change_made], axis=1)\n",
        "\n",
        "            testing_inputs.append(combined_array)\n",
        "            testing_outputs.append(stint_change_array)"
      ],
      "metadata": {
        "id": "9apYP_jci1dm"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_loss_v2(model,inputs,targets,hprev,vocab_size):\n",
        "  loss_func = nn.BCEWithLogitsLoss()\n",
        "  seq_length = len(inputs)\n",
        "  outputs = []\n",
        "  for t in range(seq_length):\n",
        "    # For each character in the input sequence, pass through RNN with previous hidden state\n",
        "    hprev,y = model(inputs[t], hprev)\n",
        "    # Gradually build up matrix of output logits of size seq_length * vocab_size - we want it at every time step do not want this.\n",
        "    # Compute cross entropy loss for seq_length actual targets against estimated distributions\n",
        "    # RuntimeError: result type Float can't be cast to the desired output type Long\n",
        "    outputs.append(y)\n",
        "    print(y)\n",
        "\n",
        "  outputs = torch.stack(outputs).squeeze(1).squeeze(1)\n",
        "  loss = loss_func(outputs ,targets)\n",
        "\n",
        "  # For truncated backprop, the next subsequence will use the final hidden state\n",
        "  # but will not backprop through it so we need to detach\n",
        "  hprev = hprev.detach()\n",
        "\n",
        "  return loss, hprev"
      ],
      "metadata": {
        "id": "B6IGFLMgrACP"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PADDING\n",
        "def add_padding(max_race_size, sequence):\n",
        "    if len(sequence) >= max_race_size:\n",
        "        return sequence[:max_race_size]\n",
        "    else:\n",
        "        padding_shape = (max_race_size - sequence.shape[0],) + sequence.shape[1:]\n",
        "        padding = np.zeros(padding_shape)\n",
        "        return np.concatenate([sequence,padding])"
      ],
      "metadata": {
        "id": "x1u-fcsLlXsA"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RNNv1c(nn.Module):\n",
        "    def __init__(self,vocab_size,hidden_size):\n",
        "        super(RNNv1c, self).__init__()\n",
        "        self.embedding =  nn.Embedding(vocab_size, hidden_size)\n",
        "        self.linear_h = nn.Linear(hidden_size,hidden_size)\n",
        "        self.linear_y = nn.Linear(hidden_size,1)\n",
        "        self.tanh = nn.Tanh()\n",
        "\n",
        "    def forward(self,x,hprev):\n",
        "        h = self.tanh(self.embedding(x) + self.linear_h(hprev))\n",
        "        y = self.linear_y(h)\n",
        "        return h,y"
      ],
      "metadata": {
        "id": "ioeNLYqxox_X"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = RNNv1c(vocab_size,hidden_size)\n",
        "model.to(device)\n",
        "\n",
        "optim = torch.optim.Adam(model.parameters(), lr = lr)\n",
        "\n",
        "n, p = 0, 0\n",
        "while n<=iterations:\n",
        "  hprev = torch.zeros(hidden_size, device=device) # reset RNN memory\n",
        "\n",
        "  # Why apply padding here\n",
        "  inputs = add_padding(int(max_race_size),training_inputs[p])\n",
        "  outputs = add_padding(int(max_race_size),training_outputs[p])\n",
        "\n",
        "  # Extract next subsequence of characters\n",
        "  inputs = torch.tensor(training_inputs[p],dtype=torch.long, device=device)\n",
        "  targets = torch.tensor(training_outputs[p],dtype=torch.float32, device=device)\n",
        "\n",
        "  # Compute loss for current subsequence\n",
        "  loss, hprev = calculate_loss_v2(model,inputs,targets,hprev,vocab_size)\n",
        "  optim.zero_grad()\n",
        "  loss.backward()\n",
        "  optim.step()\n",
        "\n",
        "  if n % 500 == 0:\n",
        "    print('[{:}] Loss: {:.2f}'.format(n,loss.item()))\n",
        "    check_accuracy()\n",
        "\n",
        "  p += 1 # move data pointer\n",
        "  n += 1 # iteration counter\n",
        "\n",
        "  if p == int(max_race_size) - 1:\n",
        "    p = 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7euVDIyKjR57",
        "outputId": "e28e7983-4f78-4589-ac55-a189515e3e0c"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.1678],\n",
            "        [-0.1818]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[ 0.0886],\n",
            "        [-0.2326]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[ 0.1051],\n",
            "        [-0.2172]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[ 0.0840],\n",
            "        [-0.2154]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[ 0.0911],\n",
            "        [-0.2116]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[ 0.0897],\n",
            "        [-0.2128]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[ 0.0886],\n",
            "        [-0.2131]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[ 0.0884],\n",
            "        [-0.2130]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[ 0.0886],\n",
            "        [-0.2130]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[ 0.0887],\n",
            "        [-0.2130]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[ 0.0886],\n",
            "        [-0.2130]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[ 0.0886],\n",
            "        [-0.2130]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[ 0.0886],\n",
            "        [-0.2130]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[-0.1869],\n",
            "        [-0.2130]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[0.0393],\n",
            "        [0.0520]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[0.0706],\n",
            "        [0.1130]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[0.1169],\n",
            "        [0.1166]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[0.0916],\n",
            "        [0.0911]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[0.0897],\n",
            "        [0.0897]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[0.0883],\n",
            "        [0.0890]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[0.0888],\n",
            "        [0.0888]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[0.0887],\n",
            "        [0.0886]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[0.0886],\n",
            "        [0.0886]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[0.0886],\n",
            "        [0.0886]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[0.0886],\n",
            "        [0.0886]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[0.0886],\n",
            "        [0.0886]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[0.0886],\n",
            "        [0.0886]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[0.0886],\n",
            "        [0.0886]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[0.0886],\n",
            "        [0.0886]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[-0.1869],\n",
            "        [ 0.0886]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[0.0393],\n",
            "        [0.0886]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[0.0706],\n",
            "        [0.0886]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[0.1169],\n",
            "        [0.0886]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[0.0916],\n",
            "        [0.0886]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[0.0897],\n",
            "        [0.0886]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[0.0883],\n",
            "        [0.0886]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[0.0888],\n",
            "        [0.0886]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[0.0887],\n",
            "        [0.0886]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[0.0886],\n",
            "        [0.0886]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[0.0886],\n",
            "        [0.0886]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[0.0886],\n",
            "        [0.0886]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[0.0886],\n",
            "        [0.0886]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[-0.1869],\n",
            "        [ 0.0886]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[0.0393],\n",
            "        [0.0886]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[0.0706],\n",
            "        [0.0886]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[0.1169],\n",
            "        [0.0886]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[0.0916],\n",
            "        [0.0886]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[0.0897],\n",
            "        [0.0886]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[0.0883],\n",
            "        [0.0886]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[0.0888],\n",
            "        [0.0886]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[0.0887],\n",
            "        [0.0886]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[0.0886],\n",
            "        [0.0886]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[0.0886],\n",
            "        [0.0886]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[0.0886],\n",
            "        [0.0886]], grad_fn=<AddmmBackward0>)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Target size (torch.Size([54])) must be the same as input size (torch.Size([54, 2, 1]))",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-113-9cd9361c1f41>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m   \u001b[0;31m# Compute loss for current subsequence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m   \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhprev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_loss_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhprev\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m   \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m   \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-110-5acabf44fb29>\u001b[0m in \u001b[0;36mcalculate_loss_v2\u001b[0;34m(model, inputs, targets, hprev, vocab_size)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m   \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m   \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m   \u001b[0;31m# For truncated backprop, the next subsequence will use the final hidden state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         return F.binary_cross_entropy_with_logits(\n\u001b[0m\u001b[1;32m    820\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m             \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbinary_cross_entropy_with_logits\u001b[0;34m(input, target, weight, size_average, reduce, reduction, pos_weight)\u001b[0m\n\u001b[1;32m   3622\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3623\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3624\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m   3625\u001b[0m             \u001b[0;34mf\"Target size ({target.size()}) must be the same as input size ({input.size()})\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3626\u001b[0m         )\n",
            "\u001b[0;31mValueError\u001b[0m: Target size (torch.Size([54])) must be the same as input size (torch.Size([54, 2, 1]))"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Tb7mbKxdr7xv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}