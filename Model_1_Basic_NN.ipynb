{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "15snMOHrwpWO_qNjB-uqVjM_LwzWq-JuP",
      "authorship_tag": "ABX9TyNdeULLyerBlrssJTvH/ZlR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mistryvivek/YRKCS-PRBX/blob/main/Model_1_Basic_NN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9BKFIobTm36L"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import random\n",
        "import pandas as pd\n",
        "from torch.nn.utils.rnn import pad_sequence"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class RNN(nn.Module):\n",
        "    def __init__(self,max_laps,hidden_size):\n",
        "        super(RNN, self).__init__()\n",
        "        self.embedding =  nn.Embedding(max_laps, hidden_size)\n",
        "        self.linear_h = nn.Linear(hidden_size,hidden_size)\n",
        "        self.linear_y = nn.Linear(hidden_size,max_laps)\n",
        "        self.tanh = nn.Tanh()\n",
        "\n",
        "    def forward(self,x,hprev):\n",
        "        h = self.tanh(self.embedding(x) + self.linear_h(hprev))\n",
        "        y = self.linear_y(h)\n",
        "        return h,y"
      ],
      "metadata": {
        "id": "bWcnkSnqniIl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loss function (Based upon wk11 practical)\n",
        "\n",
        "* Vocab size is not relevent here - going to give it binary classification values anyway.\n",
        "* Everything else can be applied for time series: use Cross Entropy Loss, Length of the race = seq_len.\n",
        "* For each lap, pass through the RNN with previous hidden state and build up hte matrix of outputs.\n",
        "* Detact the previous hidden state as a new one will be generated."
      ],
      "metadata": {
        "id": "S81x8lmwJ68-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_loss(model,inputs,targets,hprev,max_tyre_life):\n",
        "  loss_func = nn.BCEWithLogitsLoss()\n",
        "  seq_length = len(inputs)\n",
        "  #outputs = torch.zeros(0, max_laps)\n",
        "  #print(outputs.shape)\n",
        "  for t in range(seq_length):\n",
        "    # For each character in the input sequence, pass through RNN with previous hidden state\n",
        "    hprev,y = model(torch.tensor([inputs[t]]),hprev)\n",
        "    # Gradually build up matrix of output logits of size seq_length * max_tyre_life\n",
        "    #outputs = torch.cat((outputs ,y))\n",
        "\n",
        "  # Compute cross entropy loss for seq_length actual targets against estimated distributions\n",
        "  loss = loss_func(y,targets.unsqueeze(0))\n",
        "\n",
        "  # For truncated backprop, the next subsequence will use the final hidden state\n",
        "  # but will not backprop through it so we need to detach\n",
        "  hprev = hprev.detach()\n",
        "\n",
        "  return loss, hprev"
      ],
      "metadata": {
        "id": "4b01se5zoVVe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# My dataset - how to format?\n",
        "\n",
        "* Training and testing\n",
        "* inputs_training/ inputs_testing/  outputs_testing/ output_training\n",
        "* For now, it will all just be a 2d array.\n",
        "\n",
        "ERROR:\n",
        "\n",
        "```2551     return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)\n",
        "   2552\n",
        "   2553\n",
        "\n",
        "IndexError: index out of range in self```"
      ],
      "metadata": {
        "id": "icgJLYuiNA2T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BASE_PATH = r\"/content/drive/MyDrive/prbx_data/v1/\"\n",
        "max_race_size = 0\n",
        "max_tyre_life = 0"
      ],
      "metadata": {
        "id": "vjXV6o1kOB_-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TRAINING\n",
        "training_inputs = []\n",
        "training_outputs = []\n",
        "\n",
        "RaceCalender22 = pd.read_csv(BASE_PATH + r\"2022/eventCalender2022.csv\")\n",
        "for _, row in RaceCalender22.iterrows():\n",
        "    if row['EventFormat'] != 'testing':\n",
        "        # Load race data\n",
        "        TempRaceLoad = pd.read_csv(\n",
        "            BASE_PATH + f\"2022/{row['RoundNumber']}_{row['OfficialEventName']}/{row['RoundNumber']}_{row['OfficialEventName']}_Race.csv\".replace(\" \", \"_\")\n",
        "        )\n",
        "        for driver in TempRaceLoad['Driver'].unique():\n",
        "            # Filter data for the specific driver and sort by LapNumber\n",
        "            TempRaceLoadDriver = TempRaceLoad[TempRaceLoad['Driver'] == driver].sort_values(by='LapNumber', ascending=True)\n",
        "\n",
        "            if max(TempRaceLoadDriver['LapNumber']) > max_race_size:\n",
        "                max_race_size = max(TempRaceLoadDriver['LapNumber'])\n",
        "\n",
        "            \"\"\"if max(TempRaceLoadDriver['TyreLife']) > max_tyre_life:\n",
        "                max_tyre_life = max(TempRaceLoadDriver['TyreLife'])\"\"\"\n",
        "\n",
        "            # Extract tyre life and stint columns\n",
        "            tyre_life_array = TempRaceLoadDriver['TyreLife'].values\n",
        "            stint_array = TempRaceLoadDriver['Stint'].values\n",
        "\n",
        "            # Create the stint change array\n",
        "            stint_change_array = []\n",
        "            for i in range(len(stint_array)):\n",
        "                if i == len(stint_array) - 1:  # Last lap\n",
        "                    stint_change_array.append(False)  # Treat as no change\n",
        "                else:\n",
        "                    stint_change_array.append(stint_array[i] != stint_array[i + 1])\n",
        "\n",
        "            stint_change_array = np.array(stint_change_array)\n",
        "\n",
        "            # Ensure tyre_life_array and stint_change_array are properly formatted\n",
        "            tyre_life_array = torch.tensor(tyre_life_array, dtype=torch.long)\n",
        "            stint_change_array = torch.tensor(stint_change_array, dtype=torch.float32)\n",
        "            # Add to training data\n",
        "            training_inputs.append(tyre_life_array)\n",
        "            training_outputs.append(stint_change_array)"
      ],
      "metadata": {
        "id": "ub0zgeNtND3l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TESTING\n",
        "testing_inputs = []\n",
        "testing_outputs = []\n",
        "\n",
        "RaceCalender23 = pd.read_csv(BASE_PATH + r\"2023/eventCalender2023.csv\")\n",
        "for _, row in RaceCalender23.iterrows():\n",
        "    if row['EventFormat'] != 'testing':\n",
        "        # Load race data\n",
        "        TempRaceLoad = pd.read_csv(\n",
        "            BASE_PATH + f\"2023/{row['RoundNumber']}_{row['OfficialEventName']}/{row['RoundNumber']}_{row['OfficialEventName']}_Race.csv\".replace(\" \", \"_\")\n",
        "        )\n",
        "        for driver in TempRaceLoad['Driver'].unique():\n",
        "            # Filter data for the specific driver and sort by LapNumber\n",
        "            TempRaceLoadDriver = TempRaceLoad[TempRaceLoad['Driver'] == driver].sort_values(by='LapNumber', ascending=True)\n",
        "\n",
        "            if max(TempRaceLoadDriver['LapNumber']) > max_race_size:\n",
        "                max_race_size = max(TempRaceLoadDriver['LapNumber'])\n",
        "\n",
        "            if max(TempRaceLoadDriver['TyreLife']) > max_tyre_life:\n",
        "                max_tyre_life = max(TempRaceLoadDriver['TyreLife'])\n",
        "\n",
        "            # Extract tyre life and stint columns\n",
        "            tyre_life_array = TempRaceLoadDriver['TyreLife'].values\n",
        "            stint_array = TempRaceLoadDriver['Stint'].values\n",
        "\n",
        "            # Create the stint change array\n",
        "            stint_change_array = []\n",
        "            for i in range(len(stint_array)):\n",
        "                if i == len(stint_array) - 1:  # Last lap\n",
        "                    stint_change_array.append(False)  # Treat as no change\n",
        "                else:\n",
        "                    stint_change_array.append(stint_array[i] != stint_array[i + 1])\n",
        "\n",
        "            stint_change_array = np.array(stint_change_array)\n",
        "\n",
        "            # Ensure tyre_life_array and stint_change_array are properly formatted\n",
        "            tyre_life_array = torch.tensor(tyre_life_array, dtype=torch.long)\n",
        "            stint_change_array = torch.tensor(stint_change_array, dtype=torch.float32)\n",
        "\n",
        "            # Add to testing data\n",
        "            testing_inputs.append(tyre_life_array)\n",
        "            testing_outputs.append(stint_change_array)"
      ],
      "metadata": {
        "id": "MQHvjvglTQNF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training the model"
      ],
      "metadata": {
        "id": "4015h9tIT5Lj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_size = 1\n",
        "lr = 0.01\n",
        "iterations = 2000\n",
        "max_race_size = int(max_race_size)"
      ],
      "metadata": {
        "id": "s-1yQVYSUMBf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pad_with_last_value(tensor, max_race_size):\n",
        "    if len(tensor) > max_race_size:\n",
        "        return\n",
        "\n",
        "    last_value = tensor[-1]\n",
        "    pad_size = max_race_size - len(tensor)\n",
        "    padding = torch.full((pad_size,), last_value, dtype=tensor.dtype)\n",
        "    return torch.cat((tensor, padding))"
      ],
      "metadata": {
        "id": "_Km1hhBTVm7G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = RNN(max_race_size, hidden_size)\n",
        "\n",
        "optim = torch.optim.Adam(model.parameters(), lr = lr)\n",
        "\n",
        "n, p = 0, 0\n",
        "while n<=iterations:\n",
        "  hprev = torch.zeros(hidden_size,) # reset RNN memory\n",
        "\n",
        "  inputs = training_inputs[p]\n",
        "  targets = training_outputs[p]\n",
        "\n",
        "  inputs = pad_with_last_value(inputs,max_race_size)\n",
        "  targets = pad_with_last_value(targets,max_race_size)\n",
        "\n",
        "\n",
        "  # Compute loss for current subsequence\n",
        "  loss, hprev = calculate_loss(model,inputs,targets,hprev,max_race_size)\n",
        "  optim.zero_grad()\n",
        "  loss.backward()\n",
        "  optim.step()\n",
        "\n",
        "  if n % 500 == 0:\n",
        "    print('[{:}] Loss: {:.2f}'.format(n,loss.item()))\n",
        "\n",
        "  n += 1 # iteration counter\n",
        "  p += 1 # dataset counter\n",
        "\n",
        "  #Restart to the front of the list.\n",
        "  if p == len(training_inputs) -1:\n",
        "    p = 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oxZaedx7T8Ch",
        "outputId": "d76e15eb-bde8-4a0a-ff12-e95fc40c6f00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0] Loss: 0.73\n",
            "[500] Loss: 0.70\n",
            "[1000] Loss: 0.73\n",
            "[1500] Loss: 0.30\n",
            "[2000] Loss: 0.52\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#How can we calculate accuracy for this basic model?\n",
        "\n",
        "* Say is probability is above 80% percent pit, otherwise don't pit.\n",
        "* Want at least one right pit stop identification to class it as match."
      ],
      "metadata": {
        "id": "0LwWuY-xc-c_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for t in range(len(testing_inputs[1])):\n",
        "  # For each character in the input sequence, pass through RNN with previous hidden state\n",
        "  hprev,y = model(torch.tensor([testing_inputs[1][t]]),hprev)\n",
        "probabilities = torch.sigmoid(y)"
      ],
      "metadata": {
        "id": "Vdeo3NuEsA3b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "probabilities"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fEWvwpJ2sT2v",
        "outputId": "e5158510-74ed-4739-d974-813a3228c96f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.0000e+00, 8.6562e-01, 1.0000e+00, 1.0000e+00, 1.0000e+00, 9.9097e-01,\n",
              "         1.0000e+00, 1.0000e+00, 1.0000e+00, 9.9995e-01, 1.0000e+00, 1.0000e+00,\n",
              "         4.6142e-01, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 9.9996e-01,\n",
              "         1.0000e+00, 1.0000e+00, 1.2703e-04, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
              "         1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
              "         1.0000e+00, 1.0000e+00, 8.2599e-01, 1.0000e+00, 9.7841e-01, 8.7177e-01,\n",
              "         1.0000e+00, 9.4194e-01, 1.0000e+00, 8.0562e-01, 1.0000e+00, 1.0000e+00,\n",
              "         1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
              "         1.0000e+00, 1.0000e+00, 7.8653e-08, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
              "         1.0000e+00, 1.0000e+00, 9.9970e-01, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
              "         1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
              "         1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
              "         1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00]],\n",
              "       grad_fn=<SigmoidBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for t in range(len(training_inputs[0])):\n",
        "  # For each character in the input sequence, pass through RNN with previous hidden state\n",
        "  hprev,y = model(torch.tensor([training_inputs[0][t]]),hprev)\n",
        "probabilities = torch.sigmoid(y)"
      ],
      "metadata": {
        "id": "8Xf23b3VsfGF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "probabilities"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mxvmEKgxsizL",
        "outputId": "88dc675a-6ad8-4f3e-eda4-71712ffc9f95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[9.6322e-01, 6.7875e-03, 1.0000e+00, 1.0000e+00, 1.0000e+00, 9.9910e-01,\n",
              "         1.0000e+00, 1.0000e+00, 1.0000e+00, 4.3098e-03, 9.9997e-01, 1.0000e+00,\n",
              "         9.7848e-01, 9.9999e-01, 9.9996e-01, 1.0000e+00, 9.9531e-01, 9.6623e-01,\n",
              "         1.0000e+00, 1.0000e+00, 7.6865e-05, 9.9287e-01, 1.0000e+00, 1.0000e+00,\n",
              "         1.0000e+00, 1.0000e+00, 9.8730e-01, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
              "         9.9860e-01, 1.9398e-08, 1.5346e-03, 1.0000e+00, 9.9837e-01, 2.8660e-01,\n",
              "         1.0000e+00, 1.0000e+00, 1.0000e+00, 9.2517e-01, 9.8466e-01, 8.7852e-01,\n",
              "         1.0000e+00, 1.0000e+00, 1.0000e+00, 9.9989e-01, 1.0000e+00, 1.0000e+00,\n",
              "         1.0000e+00, 1.0000e+00, 5.5465e-02, 1.0000e+00, 1.0000e+00, 9.9999e-01,\n",
              "         1.0000e+00, 1.0000e+00, 9.9975e-01, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
              "         1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
              "         1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
              "         1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00]],\n",
              "       grad_fn=<SigmoidBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "def evaluate_model(inputs, outputs, tolerance=3):\n",
        "    total_correct = 0\n",
        "    total_predictions = 0\n",
        "\n",
        "    for seq_idx in range(len(inputs)):\n",
        "        # Initialize hidden state for each sequence\n",
        "        hprev = torch.zeros(hidden_size,)\n",
        "\n",
        "        # Get the input and target sequences\n",
        "        input = inputs[seq_idx]\n",
        "        output = outputs[seq_idx].numpy()\n",
        "\n",
        "        # Step through the input sequence and get predicted probabilities\n",
        "        for t in range(len(input)):\n",
        "            hprev, y = model(torch.tensor([input[t]]), hprev)\n",
        "            predicted_pits = torch.sigmoid(y) # Apply sigmoid to logits to get probabilities\n",
        "\n",
        "        predicted_pits = predicted_pits.detach().numpy()[0]\n",
        "        predicted_pits = predicted_pits > 0.5\n",
        "        actual_pits = output == 1.0\n",
        "\n",
        "        # Now check accuracy for this sequence with tolerance\n",
        "        correct_count = 0\n",
        "        total_predictions_for_sequence = 0\n",
        "\n",
        "        for predicted_pit_idx in range(len(predicted_pits)):\n",
        "          if predicted_pits[predicted_pit_idx]:  # If a pit stop is predicted\n",
        "              total_predictions += 1\n",
        "\n",
        "              # Calculate the tolerance window around the predicted pit\n",
        "              start_idx = max(0, predicted_pit_idx - tolerance)\n",
        "              end_idx = min(len(actual_pits), predicted_pit_idx + tolerance + 1)\n",
        "\n",
        "              # Check if there's any actual pit stop within this window using NumPy\n",
        "              if np.any(actual_pits[start_idx:end_idx] == 1):  # If there's a pit stop in this window\n",
        "                  correct_count += 1\n",
        "                  break\n",
        "\n",
        "        total_correct += correct_count\n",
        "\n",
        "    # Calculate overall accuracy\n",
        "    accuracy = total_correct / total_predictions if total_predictions > 0 else 0\n",
        "    return accuracy * 100"
      ],
      "metadata": {
        "id": "taRdShcOzWeY"
      },
      "execution_count": 225,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Plot to see what this basic model has remembered - probably just averages"
      ],
      "metadata": {
        "id": "dTW5sj-0rpEs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Validating my data"
      ],
      "metadata": {
        "id": "EQrJxg_CXdKZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(training_inputs) == len(training_outputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8i2tG_ZxXEmu",
        "outputId": "3297703b-7732-44dc-f521-e4f2b3b13af6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_inputs[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QT6aLRA5dPL9",
        "outputId": "37147c4b-5589-466a-bfcf-8f1533d49bc9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([54])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_outputs[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QuompqxedSuP",
        "outputId": "53e49d68-382c-4242-df76-b3b2b43f69f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([54])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    }
  ]
}